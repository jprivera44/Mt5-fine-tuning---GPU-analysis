{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ef5c5-b207-4afa-888f-0bbfcf904c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "\n",
    "# Import large Mt5 model\n",
    "# bring in dataset\n",
    "# Fine tune\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ca90da3-e1ed-4022-8015-0744b984766f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:52.672775Z",
     "iopub.status.busy": "2023-07-16T21:48:52.671995Z",
     "iopub.status.idle": "2023-07-16T21:48:52.991989Z",
     "shell.execute_reply": "2023-07-16T21:48:52.991420Z",
     "shell.execute_reply.started": "2023-07-16T21:48:52.672760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_es (/root/.cache/huggingface/datasets/squad_es/v1.1.0/1.1.0/bcada4f600192451443b95e24f609325705c5185b8aad97bffa8bc3784a867ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3649e257cc040f1bfe7a0b502165a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Bring in dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_es\",'v1.1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4de7879-ebb6-41a7-8892-fe1ec7b051da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T20:44:18.228549Z",
     "iopub.status.busy": "2023-07-16T20:44:18.227669Z",
     "iopub.status.idle": "2023-07-16T20:44:18.233107Z",
     "shell.execute_reply": "2023-07-16T20:44:18.232517Z",
     "shell.execute_reply.started": "2023-07-16T20:44:18.228515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87595\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d9c96-64c4-4be2-aed6-c1a5b635d2b5",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "094a6a02-7272-42cd-bb16-10c5f4c38f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:48:58.871643Z",
     "iopub.status.busy": "2023-07-16T22:48:58.870921Z",
     "iopub.status.idle": "2023-07-16T22:49:00.531223Z",
     "shell.execute_reply": "2023-07-16T22:49:00.530530Z",
     "shell.execute_reply.started": "2023-07-16T22:48:58.871608Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/google/mt5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/4764ec347af4d2d6286acbe1d9d630ac0afd8554a4c4a64170e0b663fd2e2412.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/0d7d5b3fc19bf58d4b274990c8bcf5e307726bc18d95f40a1436dfb6a0892f85.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/afba33be693521ccefbde6d03b93b5c517d7108ba31f6c08000ed52c2cea45c9.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1 and 2: Combine context and question, format the answer\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5TokenizerFast.from_pretrained('google/mt5-base')\n",
    "\n",
    "\n",
    "def prep_data(train_subset):\n",
    "\n",
    "    # Create new lists for our inputs and answers\n",
    "    input_ids = []\n",
    "    input_attn_msk = []\n",
    "    answers_ids = []\n",
    "\n",
    "    for id_value, title_value, context_value, q_value, a_value in zip(train_subset['id'], train_subset['title'], train_subset['context'],train_subset['question'],train_subset['answers']):\n",
    "\n",
    "        #INPUTS\n",
    "        # Combine the context and question into a single string\n",
    "        input_str = context_value + \" \" + q_value\n",
    "        #print(input_str)\n",
    "\n",
    "        #tokenize the inputs\n",
    "        inputs = tokenizer(input_str, truncation=True, padding='max_length', max_length=512)\n",
    "        #print(inputs.input_ids)\n",
    "        input_ids.append(inputs.input_ids)\n",
    "        input_attn_msk.append(inputs.attention_mask)\n",
    "\n",
    "\n",
    "        #ANSWERS\n",
    "        answers = a_value['text']\n",
    "        answers_tokens = tokenizer(a_value['text'], truncation=True, padding='max_length', max_length=128)\n",
    "        answers_ids.append(answers_tokens.input_ids)\n",
    "\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "\n",
    "    # Iterate over the values from each list\n",
    "    for input_id, attention_mask, label  in zip(input_ids, input_attn_msk, answers_ids):\n",
    "        # Create a dictionary with the desired keys\n",
    "        data_dict = {\n",
    "            'input_ids': torch.tensor(input_id),\n",
    "            'attention_mask': torch.tensor(attention_mask),\n",
    "            'labels': torch.tensor(label)\n",
    "\n",
    "        }\n",
    "\n",
    "        # Append the dictionary to the result list\n",
    "        result_list.append(data_dict)\n",
    "\n",
    "    return(result_list)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f7c27194-b09d-4733-ae89-7758756ce27f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:52:22.377347Z",
     "iopub.status.busy": "2023-07-16T22:52:22.376938Z",
     "iopub.status.idle": "2023-07-16T22:52:23.116711Z",
     "shell.execute_reply": "2023-07-16T22:52:23.116130Z",
     "shell.execute_reply.started": "2023-07-16T22:52:22.377325Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "train_subset = dataset['train'][:1000]  # Adjust this as needed\n",
    "\n",
    "model_train_data = prep_data(train_subset)\n",
    "\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "val_subset = dataset['validation'][:100]  # Adjust this as needed\n",
    "\n",
    "model_val_data = prep_data(val_subset)\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65aea7-c5fc-406a-99e3-7c81f75492a8",
   "metadata": {},
   "source": [
    "## Data ready test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "243cc01a-bef7-40c6-bc18-dccfc03fd5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:52:27.098859Z",
     "iopub.status.busy": "2023-07-16T22:52:27.098058Z",
     "iopub.status.idle": "2023-07-16T22:52:27.102954Z",
     "shell.execute_reply": "2023-07-16T22:52:27.102465Z",
     "shell.execute_reply.started": "2023-07-16T22:52:27.098834Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset appears to be correctly structured for Trainer.\n"
     ]
    }
   ],
   "source": [
    "# replace 'train_dataset' with your dataset variable\n",
    "sample = model_train_data[0]\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"Your dataset appears to be correctly structured for Trainer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1628ea9a-ace1-4609-a954-ffefdb2de12e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:52:29.219805Z",
     "iopub.status.busy": "2023-07-16T22:52:29.218965Z",
     "iopub.status.idle": "2023-07-16T22:52:29.228642Z",
     "shell.execute_reply": "2023-07-16T22:52:29.227722Z",
     "shell.execute_reply.started": "2023-07-16T22:52:29.219759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset appears to be correctly structured for Trainer.\n"
     ]
    }
   ],
   "source": [
    "# replace 'train_dataset' with your dataset variable\n",
    "sample = model_val_data[0]\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"Your dataset appears to be correctly structured for Trainer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f781b-e08d-4151-b3a1-bda9cd7f04f4",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c8231375-e644-444d-94b6-d00528777b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:53:31.746483Z",
     "iopub.status.busy": "2023-07-16T22:53:31.746175Z",
     "iopub.status.idle": "2023-07-16T22:54:51.011330Z",
     "shell.execute_reply": "2023-07-16T22:54:51.010875Z",
     "shell.execute_reply.started": "2023-07-16T22:53:31.746460Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"/home/patrick/hugging_face/t5/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/mt5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3b7e8056d4ed71d8d7ac2dea78627c4be77ed136399c05b563d4116abfcd9418.1afec9001b62cd5a347e7fd4b664e503ca2377606e11b9ddb8ec1d7b79bc3952\n",
      "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 64\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 80\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 01:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>52.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>51.443400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>52.486700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>51.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>51.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>51.504900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>51.845000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>50.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>51.884200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>50.797500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>50.786100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>49.814400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>49.277900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>49.140900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>48.946200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>48.569700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=50.781277656555176, metrics={'train_runtime': 67.995, 'train_samples_per_second': 18.825, 'train_steps_per_second': 1.177, 'total_flos': 1534779048591360.0, 'train_loss': 50.781277656555176, 'epoch': 20.0})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Initialize the model\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")\n",
    "\n",
    "# Initialize the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=20,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=5,\n",
    ")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=validation_data,         # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf41775-d5c2-4418-9028-30143767db7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
