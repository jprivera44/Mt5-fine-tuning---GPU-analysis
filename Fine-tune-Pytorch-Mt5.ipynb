{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ef5c5-b207-4afa-888f-0bbfcf904c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps\n",
    "\n",
    "# Import large Mt5 model\n",
    "# bring in dataset\n",
    "# Fine tune\n",
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7ca90da3-e1ed-4022-8015-0744b984766f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:52.672775Z",
     "iopub.status.busy": "2023-07-16T21:48:52.671995Z",
     "iopub.status.idle": "2023-07-16T21:48:52.991989Z",
     "shell.execute_reply": "2023-07-16T21:48:52.991420Z",
     "shell.execute_reply.started": "2023-07-16T21:48:52.672760Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad_es (/root/.cache/huggingface/datasets/squad_es/v1.1.0/1.1.0/bcada4f600192451443b95e24f609325705c5185b8aad97bffa8bc3784a867ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3649e257cc040f1bfe7a0b502165a8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Bring in dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"squad_es\",'v1.1.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4de7879-ebb6-41a7-8892-fe1ec7b051da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T20:44:18.228549Z",
     "iopub.status.busy": "2023-07-16T20:44:18.227669Z",
     "iopub.status.idle": "2023-07-16T20:44:18.233107Z",
     "shell.execute_reply": "2023-07-16T20:44:18.232517Z",
     "shell.execute_reply.started": "2023-07-16T20:44:18.228515Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87595\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75d9c96-64c4-4be2-aed6-c1a5b635d2b5",
   "metadata": {},
   "source": [
    "## Data Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5cfe7edb-df61-45b6-982b-cf9cea459d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:06:14.995650Z",
     "iopub.status.busy": "2023-07-16T22:06:14.994859Z",
     "iopub.status.idle": "2023-07-16T22:06:15.004084Z",
     "shell.execute_reply": "2023-07-16T22:06:15.003538Z",
     "shell.execute_reply.started": "2023-07-16T22:06:14.995624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id value 5733be284776f41900661182\n",
      "id value 5733be284776f4190066117f\n",
      "id value 5733be284776f41900661180\n",
      "id value 5733be284776f41900661181\n",
      "id value 5733be284776f4190066117e\n",
      "id value 5733bf84d058e614000b61be\n",
      "id value 5733bf84d058e614000b61bf\n",
      "id value 5733bf84d058e614000b61c0\n",
      "id value 5733bf84d058e614000b61bd\n",
      "id value 5733bf84d058e614000b61c1\n"
     ]
    }
   ],
   "source": [
    "# Step 1 and 2: Combine context and question, format the answer\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "train_subset = dataset['train'][:10]  # Adjust this as needed\n",
    "\n",
    "# Create new lists for our inputs and answers\n",
    "inputs = []\n",
    "answers = []\n",
    "\n",
    "# Iterate over each item in the train_subset data\n",
    "for id_value, title_value, context_value in zip(train_subset['id'], train_subset['title'], train_subset['context']):\n",
    "    # Combine the context and question into a single string\n",
    "    input_str = \"context: \" + context_value + \" question: \" + title_value\n",
    "    inputs.append(input_str)\n",
    "    \n",
    "    print(\"id value\",id_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd91eaba-b6f6-4646-b83a-7fbded3c12eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:11:53.571243Z",
     "iopub.status.busy": "2023-07-16T22:11:53.570549Z",
     "iopub.status.idle": "2023-07-16T22:11:53.594833Z",
     "shell.execute_reply": "2023-07-16T22:11:53.594132Z",
     "shell.execute_reply.started": "2023-07-16T22:11:53.571211Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': ['5733be284776f41900661182',\n",
       "  '5733be284776f4190066117f',\n",
       "  '5733be284776f41900661180',\n",
       "  '5733be284776f41900661181',\n",
       "  '5733be284776f4190066117e',\n",
       "  '5733bf84d058e614000b61be',\n",
       "  '5733bf84d058e614000b61bf',\n",
       "  '5733bf84d058e614000b61c0',\n",
       "  '5733bf84d058e614000b61bd',\n",
       "  '5733bf84d058e614000b61c1'],\n",
       " 'title': ['Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame',\n",
       "  'Universidad _ de _ Notre _ Dame'],\n",
       " 'context': ['Arquitectónicamente, la escuela tiene un carácter católico. Encima de la cúpula de oro del edificio principal hay una estatua dorada de la Virgen María. Inmediatamente delante del edificio principal y frente a él, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal está la Basílica del Sagrado Corazón. Inmediatamente detrás de la basílica está la Gruta, un lugar mariano de oración y reflexión. Es una réplica de la gruta de Lourdes, Francia, donde la Virgen María supuestamente se le apareció a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una línea directa que se conecta a través de 3 estatuas y la Cúpula de Oro), hay una simple y moderna estatua de piedra de María.',\n",
       "  'Arquitectónicamente, la escuela tiene un carácter católico. Encima de la cúpula de oro del edificio principal hay una estatua dorada de la Virgen María. Inmediatamente delante del edificio principal y frente a él, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal está la Basílica del Sagrado Corazón. Inmediatamente detrás de la basílica está la Gruta, un lugar mariano de oración y reflexión. Es una réplica de la gruta de Lourdes, Francia, donde la Virgen María supuestamente se le apareció a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una línea directa que se conecta a través de 3 estatuas y la Cúpula de Oro), hay una simple y moderna estatua de piedra de María.',\n",
       "  'Arquitectónicamente, la escuela tiene un carácter católico. Encima de la cúpula de oro del edificio principal hay una estatua dorada de la Virgen María. Inmediatamente delante del edificio principal y frente a él, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal está la Basílica del Sagrado Corazón. Inmediatamente detrás de la basílica está la Gruta, un lugar mariano de oración y reflexión. Es una réplica de la gruta de Lourdes, Francia, donde la Virgen María supuestamente se le apareció a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una línea directa que se conecta a través de 3 estatuas y la Cúpula de Oro), hay una simple y moderna estatua de piedra de María.',\n",
       "  'Arquitectónicamente, la escuela tiene un carácter católico. Encima de la cúpula de oro del edificio principal hay una estatua dorada de la Virgen María. Inmediatamente delante del edificio principal y frente a él, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal está la Basílica del Sagrado Corazón. Inmediatamente detrás de la basílica está la Gruta, un lugar mariano de oración y reflexión. Es una réplica de la gruta de Lourdes, Francia, donde la Virgen María supuestamente se le apareció a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una línea directa que se conecta a través de 3 estatuas y la Cúpula de Oro), hay una simple y moderna estatua de piedra de María.',\n",
       "  'Arquitectónicamente, la escuela tiene un carácter católico. Encima de la cúpula de oro del edificio principal hay una estatua dorada de la Virgen María. Inmediatamente delante del edificio principal y frente a él, hay una estatua de cobre de Cristo con los brazos levantados con la leyenda \"Venite Ad Me Omnes\". Junto al edificio principal está la Basílica del Sagrado Corazón. Inmediatamente detrás de la basílica está la Gruta, un lugar mariano de oración y reflexión. Es una réplica de la gruta de Lourdes, Francia, donde la Virgen María supuestamente se le apareció a Santa Bernadette Soubirous en 1858. Al final de la unidad principal (y en una línea directa que se conecta a través de 3 estatuas y la Cúpula de Oro), hay una simple y moderna estatua de piedra de María.',\n",
       "  \"Como en la mayoría de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicación. Los nueve puntos de venta dirigidos por estudiantes incluyen tres periódicos, tanto una estación de radio y televisión, y varias revistas y diarios. Comenzó como una revista de una página en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicación colegial continua más antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al año y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los periódicos tienen diferentes intereses de publicación, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicación independiente y no tiene un asesor de la facultad ni ninguna supervisión editorial de la Universidad. En 1987, cuando algunos estudiantes creían que The Observer comenzó a mostrar un sesgo conservador, un periódico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes creían que el periódico mostraba un sesgo liberal, el periódico conservador Irish Rover entró en producción. Ningún periódico es publicado tan a menudo como The Observer; Sin embargo, los tres están distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigación en ciencias políticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayoría de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicación. Los nueve puntos de venta dirigidos por estudiantes incluyen tres periódicos, tanto una estación de radio y televisión, y varias revistas y diarios. Comenzó como una revista de una página en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicación colegial continua más antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al año y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los periódicos tienen diferentes intereses de publicación, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicación independiente y no tiene un asesor de la facultad ni ninguna supervisión editorial de la Universidad. En 1987, cuando algunos estudiantes creían que The Observer comenzó a mostrar un sesgo conservador, un periódico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes creían que el periódico mostraba un sesgo liberal, el periódico conservador Irish Rover entró en producción. Ningún periódico es publicado tan a menudo como The Observer; Sin embargo, los tres están distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigación en ciencias políticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayoría de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicación. Los nueve puntos de venta dirigidos por estudiantes incluyen tres periódicos, tanto una estación de radio y televisión, y varias revistas y diarios. Comenzó como una revista de una página en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicación colegial continua más antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al año y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los periódicos tienen diferentes intereses de publicación, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicación independiente y no tiene un asesor de la facultad ni ninguna supervisión editorial de la Universidad. En 1987, cuando algunos estudiantes creían que The Observer comenzó a mostrar un sesgo conservador, un periódico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes creían que el periódico mostraba un sesgo liberal, el periódico conservador Irish Rover entró en producción. Ningún periódico es publicado tan a menudo como The Observer; Sin embargo, los tres están distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigación en ciencias políticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayoría de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicación. Los nueve puntos de venta dirigidos por estudiantes incluyen tres periódicos, tanto una estación de radio y televisión, y varias revistas y diarios. Comenzó como una revista de una página en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicación colegial continua más antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al año y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los periódicos tienen diferentes intereses de publicación, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicación independiente y no tiene un asesor de la facultad ni ninguna supervisión editorial de la Universidad. En 1987, cuando algunos estudiantes creían que The Observer comenzó a mostrar un sesgo conservador, un periódico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes creían que el periódico mostraba un sesgo liberal, el periódico conservador Irish Rover entró en producción. Ningún periódico es publicado tan a menudo como The Observer; Sin embargo, los tres están distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigación en ciencias políticas, Beyond Politics, hizo su debut.\",\n",
       "  \"Como en la mayoría de las otras universidades, los estudiantes de Notre Dame tienen una serie de medios de comunicación. Los nueve puntos de venta dirigidos por estudiantes incluyen tres periódicos, tanto una estación de radio y televisión, y varias revistas y diarios. Comenzó como una revista de una página en septiembre de 1876, la revista Scholastic se publica dos veces al mes y afirma ser la publicación colegial continua más antigua de los Estados Unidos. La otra revista, The Juggler, se publica dos veces al año y se centra en la literatura estudiantil y el arte. El anuario Dome se publica anualmente. Los periódicos tienen diferentes intereses de publicación, con The Observer publicado diariamente y principalmente reportando la universidad y otras noticias, y el personal de estudiantes de Notre Dame y Saint Mary 's College. A diferencia de Scholastic y The Dome, The Observer es una publicación independiente y no tiene un asesor de la facultad ni ninguna supervisión editorial de la Universidad. En 1987, cuando algunos estudiantes creían que The Observer comenzó a mostrar un sesgo conservador, un periódico liberal, Common Sense fue publicado. Del mismo modo, en 2003, cuando otros estudiantes creían que el periódico mostraba un sesgo liberal, el periódico conservador Irish Rover entró en producción. Ningún periódico es publicado tan a menudo como The Observer; Sin embargo, los tres están distribuidos a todos los estudiantes. Finalmente, en la primavera de 2008, una revista de pregrado para investigación en ciencias políticas, Beyond Politics, hizo su debut.\"],\n",
       " 'question': ['¿A quién acudió la Virgen María supuestamente en 1858 en Lourdes France?',\n",
       "  '¿Qué hay frente al edificio principal de Notre Dame?',\n",
       "  'La Basílica del Sagrado Corazón en Notre Dame está al lado de qué estructura?',\n",
       "  '¿Qué es la Gruta de Notre Dame?',\n",
       "  '¿Qué se encuentra en la parte superior del edificio principal de Notre Dame?',\n",
       "  '¿Cuándo comenzó la revista escolástica de Notre Dame?',\n",
       "  '¿Con qué frecuencia se publica el Juggler de Notre Dame?',\n",
       "  '¿Cómo se llama el periódico estudiantil diario de Notre Dame?',\n",
       "  '¿Cuántos periódicos de estudiantes se encuentran en Notre Dame?',\n",
       "  '¿En qué año comenzó la publicación del periódico estudiantil Common Sense en Notre Dame?'],\n",
       " 'answers': [{'text': ['Santa Bernadette Soubirous'], 'answer_start': [572]},\n",
       "  {'text': ['una estatua de cobre de Cristo'], 'answer_start': [218]},\n",
       "  {'text': ['el edificio principal'], 'answer_start': [88]},\n",
       "  {'text': ['un lugar mariano de oración y reflexión'], 'answer_start': [430]},\n",
       "  {'text': ['una estatua dorada de la Virgen María'], 'answer_start': [114]},\n",
       "  {'text': ['de una página en septiembre de 1876'], 'answer_start': [295]},\n",
       "  {'text': ['dos veces'], 'answer_start': [504]},\n",
       "  {'text': ['The Observer'], 'answer_start': [675]},\n",
       "  {'text': ['tres periódicos'], 'answer_start': [182]},\n",
       "  {'text': ['1987'], 'answer_start': [1015]}]}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "094a6a02-7272-42cd-bb16-10c5f4c38f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T22:24:09.226043Z",
     "iopub.status.busy": "2023-07-16T22:24:09.225271Z",
     "iopub.status.idle": "2023-07-16T22:24:10.827517Z",
     "shell.execute_reply": "2023-07-16T22:24:10.826773Z",
     "shell.execute_reply.started": "2023-07-16T22:24:09.226043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/google/mt5-base/resolve/main/spiece.model from cache at /root/.cache/huggingface/transformers/4764ec347af4d2d6286acbe1d9d630ac0afd8554a4c4a64170e0b663fd2e2412.84ea7af2df68dc8db434d3160aab65cce8ac63ce5b6f7743f8c9a4a14b4f77e2\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/0d7d5b3fc19bf58d4b274990c8bcf5e307726bc18d95f40a1436dfb6a0892f85.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/google/mt5-base/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/afba33be693521ccefbde6d03b93b5c517d7108ba31f6c08000ed52c2cea45c9.28bbf90ae7962b1b7211c0ce8b2006f968c82439ec9c47e0847ba63642f9435a\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"google/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 357, 907, 1979, 15242, 53677, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 289, 259, 116096, 289, 458, 133796, 5263, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 2318, 259, 20189, 440, 259, 39909, 268, 6017, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 501, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 289, 259, 37126, 34600, 1957, 440, 17220, 269, 259, 6162, 259, 30886, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 655, 283, 27166, 422, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Input: [259, 220933, 1790, 32294, 261, 283, 259, 60876, 2812, 335, 259, 58878, 41742, 10292, 108405, 260, 642, 22472, 269, 283, 37795, 54126, 269, 16347, 426, 259, 39909, 268, 6017, 2318, 573, 99834, 262, 123281, 262, 269, 283, 89306, 278, 259, 24952, 260, 563, 87060, 259, 63047, 426, 259, 39909, 268, 6017, 259, 276, 259, 20189, 259, 262, 7938, 261, 2318, 573, 99834, 262, 269, 56333, 265, 269, 39333, 450, 595, 259, 98838, 263, 57692, 2131, 450, 283, 340, 116073, 313, 30702, 15782, 4515, 1517, 3548, 1865, 1191, 4143, 476, 440, 259, 39909, 268, 6017, 1957, 283, 364, 7590, 33858, 426, 1560, 15905, 7090, 56019, 260, 563, 87060, 269, 70774, 269, 283, 330, 7590, 33858, 1957, 283, 27166, 422, 261, 335, 5967, 207462, 268, 269, 259, 211457, 259, 276, 130784, 1790, 260, 1659, 573, 1888, 94336, 269, 283, 10937, 422, 269, 458, 133796, 261, 39233, 261, 259, 7497, 283, 89306, 278, 259, 24952, 259, 216207, 1664, 303, 340, 44406, 2711, 259, 262, 5909, 60442, 4549, 16856, 7377, 6836, 289, 259, 116096, 260, 1151, 2733, 269, 283, 259, 85890, 6017, 274, 276, 289, 573, 259, 19921, 3867, 262, 319, 303, 57850, 259, 262, 9587, 1134, 269, 381, 99834, 358, 259, 276, 283, 371, 801, 54126, 269, 23977, 506, 2318, 573, 5431, 259, 276, 4472, 262, 99834, 262, 269, 17893, 571, 269, 259, 24952, 260, 4228, 16650, 303, 259, 20347, 262, 289, 283, 1943, 11924, 426, 259, 39909, 268, 6017, 269, 259, 37126, 34600, 291, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1 and 2: Combine context and question, format the answer\n",
    "from transformers import T5TokenizerFast\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5TokenizerFast.from_pretrained('google/mt5-base')\n",
    "\n",
    "# Start with a subset of your data for testing\n",
    "train_subset = dataset['train'][:10]  # Adjust this as needed\n",
    "\n",
    "# Create new lists for our inputs and answers\n",
    "input_ids = []\n",
    "answers = []\n",
    "\n",
    "for id_value, title_value, context_value, q_value, a_value in zip(train_subset['id'], train_subset['title'], train_subset['context'],train_subset['question'],train_subset['answers']):\n",
    "    \n",
    "    \n",
    "    # Combine the context and question into a single string\n",
    "    input_str = context_value + \" \" + q_value\n",
    "    #print(input_str)\n",
    "    \n",
    "    #tokenize the inputs\n",
    "    inputs = tokenizer(input_str, truncation=True, padding='max_length', max_length=512)\n",
    "    #print(inputs.input_ids)\n",
    "    input_ids.append(inputs.input_ids)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Format the answer (assuming there's always exactly one answer)\n",
    "    #answer_str = example['answers']['text'][0]\n",
    "    #answers.append(answer_str)\n",
    "    \n",
    "\n",
    "# Check the first few examples to make sure everything looks good\n",
    "for i in range(5):\n",
    "    print(f\"Input: {input_ids[i]}\")\n",
    "    #print(f\"Answer: {answers[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3eef00-b65a-4aa6-a6bb-251cffa03d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:21:13.806771Z",
     "iopub.status.busy": "2023-07-16T21:21:13.806269Z",
     "iopub.status.idle": "2023-07-16T21:21:13.811336Z",
     "shell.execute_reply": "2023-07-16T21:21:13.810857Z",
     "shell.execute_reply.started": "2023-07-16T21:21:13.806748Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example in your dataset appears to be correctly structured.\n"
     ]
    }
   ],
   "source": [
    "# Extract one example from each tensor\n",
    "sample = {\n",
    "    'input_ids': train_data['input_ids'][0],\n",
    "    'attention_mask': train_data['attention_mask'][0],\n",
    "    'labels': train_data['labels'][0]\n",
    "}\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"An example in your dataset appears to be correctly structured.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d873825-fed8-4bdc-8244-248fddc4eae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:35.347602Z",
     "iopub.status.busy": "2023-07-16T21:48:35.346942Z",
     "iopub.status.idle": "2023-07-16T21:48:35.352889Z",
     "shell.execute_reply": "2023-07-16T21:48:35.352174Z",
     "shell.execute_reply.started": "2023-07-16T21:48:35.347577Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert train_data from dict of lists to list of dicts\n",
    "#validation_data = [dict(zip(validation_data, t)) for t in zip(*validation_data.values())]\n",
    "\n",
    "# Now train_data[0] should work, let's print it\n",
    "#print(validation_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a113f167-13d6-46fc-9718-ead5114233b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:48:39.600973Z",
     "iopub.status.busy": "2023-07-16T21:48:39.600200Z",
     "iopub.status.idle": "2023-07-16T21:48:39.603908Z",
     "shell.execute_reply": "2023-07-16T21:48:39.603472Z",
     "shell.execute_reply.started": "2023-07-16T21:48:39.600960Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert train_data from dict of lists to list of dicts\n",
    "#train_data = [dict(zip(train_data, t)) for t in zip(*train_data.values())]\n",
    "\n",
    "# Now train_data[0] should work, let's print it\n",
    "#print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f65aea7-c5fc-406a-99e3-7c81f75492a8",
   "metadata": {},
   "source": [
    "## Data ready test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "243cc01a-bef7-40c6-bc18-dccfc03fd5e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:24:22.670279Z",
     "iopub.status.busy": "2023-07-16T21:24:22.669395Z",
     "iopub.status.idle": "2023-07-16T21:24:22.675698Z",
     "shell.execute_reply": "2023-07-16T21:24:22.674905Z",
     "shell.execute_reply.started": "2023-07-16T21:24:22.670241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your dataset appears to be correctly structured for Trainer.\n"
     ]
    }
   ],
   "source": [
    "# replace 'train_dataset' with your dataset variable\n",
    "sample = validation_data[0]\n",
    "\n",
    "assert isinstance(sample, dict), \"Each item in dataset must be a dictionary\"\n",
    "assert 'input_ids' in sample, \"input_ids must be in the dataset\"\n",
    "assert 'attention_mask' in sample, \"attention_mask must be in the dataset\"\n",
    "assert 'labels' in sample, \"labels must be in the dataset\"\n",
    "\n",
    "print(\"Your dataset appears to be correctly structured for Trainer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f781b-e08d-4151-b3a1-bda9cd7f04f4",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8231375-e644-444d-94b6-d00528777b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-16T21:24:28.238507Z",
     "iopub.status.busy": "2023-07-16T21:24:28.237757Z",
     "iopub.status.idle": "2023-07-16T21:24:45.597907Z",
     "shell.execute_reply": "2023-07-16T21:24:45.597268Z",
     "shell.execute_reply.started": "2023-07-16T21:24:28.238485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/google/mt5-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/5ebfd830555547194403d6803baa127970de59b443c04b7a1a60b16a97ed3958.b589da7dac64196f9764abaf2c4c7e507cec8b14b96da3ef270d924f155062de\n",
      "Model config MT5Config {\n",
      "  \"_name_or_path\": \"/home/patrick/hugging_face/t5/mt5-base\",\n",
      "  \"architectures\": [\n",
      "    \"MT5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"mt5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250112\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/google/mt5-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3b7e8056d4ed71d8d7ac2dea78627c4be77ed136399c05b563d4116abfcd9418.1afec9001b62cd5a347e7fd4b664e503ca2377606e11b9ddb8ec1d7b79bc3952\n",
      "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
      "\n",
      "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 64\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 12\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:09, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>51.877200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12, training_loss=51.85478909810384, metrics={'train_runtime': 11.0849, 'train_samples_per_second': 17.321, 'train_steps_per_second': 1.083, 'total_flos': 230216857288704.0, 'train_loss': 51.85478909810384, 'epoch': 3.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MT5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "# Initialize the model\n",
    "model = MT5ForConditionalGeneration.from_pretrained(\"google/mt5-base\")\n",
    "\n",
    "# Initialize the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Define the compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_data,            # training dataset\n",
    "    eval_dataset=validation_data,         # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf41775-d5c2-4418-9028-30143767db7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
