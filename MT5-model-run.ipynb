{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7ac6a4-8c62-4ee7-8557-2edd6eb90910",
   "metadata": {},
   "source": [
    "# MT5 Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c903d37d-f3ae-42d7-9363-f1078dbd8e35",
   "metadata": {},
   "source": [
    "This notebook is created to be run start to finish, and runs two different versions of the GPT-Neo model developed by EleutherAI/gpt-neo.\n",
    "Versions of the model.\n",
    "- MT5 Pytorch\n",
    "- MT5 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c4e5e1-b6b8-4e32-b7d1-f41e18c17075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the models so that they are not run in the next series of scripts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434b9f0e-8e64-4fdb-9f99-46a38922e440",
   "metadata": {},
   "source": [
    "## Loading in Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532d7744-8622-47cb-abda-84dd8e5b0ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T22:19:14.190064Z",
     "iopub.status.busy": "2023-07-15T22:19:14.189497Z",
     "iopub.status.idle": "2023-07-15T22:19:16.648263Z",
     "shell.execute_reply": "2023-07-15T22:19:16.647463Z",
     "shell.execute_reply.started": "2023-07-15T22:19:14.190037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7b07c1-7412-4212-9882-0dfad3de1a42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T22:11:45.119998Z",
     "iopub.status.busy": "2023-07-15T22:11:45.119375Z",
     "iopub.status.idle": "2023-07-15T22:12:43.796596Z",
     "shell.execute_reply": "2023-07-15T22:12:43.796028Z",
     "shell.execute_reply.started": "2023-07-15T22:11:45.119973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42add39342247fcbe6f7e86c49cb057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac0f0e231b8446e93f5d597384312b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/mt5-large were not used when initializing MT5Model: ['lm_head.weight']\n",
      "- This IS expected if you are initializing MT5Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MT5Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8635ac9b4c947a7a39b863af139a559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f43ed6189444128da971dac0387112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/4.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe21cc10cc64a1986e3e5c375ee951f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import MT5Model, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Ensure the code runs on the GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = MT5Model.from_pretrained(\"google/mt5-large\")\n",
    "model = model.to(device) # Move model to GPU if available\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-large\")\n",
    "\n",
    "#article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n",
    "\n",
    "#summary = \"Weiter Verhandlung in Syrien.\"\n",
    "#inputs = tokenizer(article, return_tensors=\"pt\")\n",
    "#labels = tokenizer(text=summary, return_tensors=\"pt\")\n",
    "\n",
    "#outputs = model(input_ids=inputs[\"input_ids\"], decoder_input_ids=labels[\"input_ids\"])\n",
    "#hidden_states = outputs.last_hidden_state\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753ab0b5-e0c0-439d-902b-d5e81de691a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T22:12:54.354864Z",
     "iopub.status.busy": "2023-07-15T22:12:54.354243Z",
     "iopub.status.idle": "2023-07-15T22:14:36.046504Z",
     "shell.execute_reply": "2023-07-15T22:14:36.045812Z",
     "shell.execute_reply.started": "2023-07-15T22:12:54.354837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3f79e29df40402ea993e3afa2e7d48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/4.58G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFMT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFMT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFMT5ForConditionalGeneration for predictions without further training.\n",
      "/usr/local/lib/python3.9/dist-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFMT5ForConditionalGeneration, AutoTokenizer\n",
    "\n",
    "model = TFMT5ForConditionalGeneration.from_pretrained(\"google/mt5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/mt5-large\")\n",
    "\n",
    "#article = \"UN Offizier sagt, dass weiter verhandelt werden muss in Syrien.\"\n",
    "#summary = \"Weiter Verhandlung in Syrien.\"\n",
    "#inputs = tokenizer(article, text_target=summary, return_tensors=\"tf\")\n",
    "\n",
    "#outputs = model(**inputs)\n",
    "#loss = outputs.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebf921b-04bc-4c1d-a0d0-c035a05d5ab3",
   "metadata": {},
   "source": [
    "## Running MT5 Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cd945d-2e2d-4661-8e6d-15162ab001f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T22:19:34.781790Z",
     "iopub.status.busy": "2023-07-15T22:19:34.780964Z",
     "iopub.status.idle": "2023-07-15T22:20:49.892278Z",
     "shell.execute_reply": "2023-07-15T22:20:49.891487Z",
     "shell.execute_reply.started": "2023-07-15T22:19:34.781759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
      "Current device cuda\n",
      "Downloading config.json: 100%|██████████| 642/642 [00:00<00:00, 390kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 4.58G/4.58G [00:40<00:00, 120MB/s] \n",
      "Downloading spiece.model: 100%|██████████| 4.11M/4.11M [00:00<00:00, 62.4MB/s]\n",
      "Downloading special_tokens_map.json: 100%|██████████| 65.0/65.0 [00:00<00:00, 92.3kB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 376/376 [00:00<00:00, 334kB/s]\n",
      "['<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in']\n",
      "Generating '/tmp/nsys-report-0520.qdstrm'\n",
      "[1/7] [========================100%] report_Pytorch.nsys-rep\n",
      "[2/7] [========================100%] report_Pytorch.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /notebooks/GPT-J-model-comparison/report_Pytorch.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)    Max (ns)   StdDev (ns)               Name              \n",
      " --------  ---------------  ---------  -----------  -----------  ---------  ----------  -----------  -------------------------------\n",
      "     68.7       3713739750      50214      73958.3       6872.0          0  1585089453    8007609.3  cudaMemcpyAsync                \n",
      "     15.5        835750564          2  417875282.0  417875282.0  125372561   710378003  413661315.1  cudaFree                       \n",
      "      8.3        449099305      78964       5687.4       5379.0          0     1604271       6163.2  cudaLaunchKernel               \n",
      "      2.2        116283556        402     289262.6       1537.0          0   115616381    5766338.1  cudaStreamIsCapturing_v10000   \n",
      "      1.5         79369683      20764       3822.5       2575.0          0       85786       6013.7  cudaStreamSynchronize          \n",
      "      1.3         69731540        405     172176.6     137852.0       6885     2898305     172949.1  cudaMalloc                     \n",
      "      1.1         58522732      10802       5417.8       5060.0          0      562709       5644.6  cudaMemsetAsync                \n",
      "      0.6         31662271      32112        986.0        891.0          0      267647       1572.7  cudaStreamGetCaptureInfo_v10010\n",
      "      0.6         30664385      10704       2864.8       2817.0          0       49006       1075.7  cudaEventQuery                 \n",
      "      0.4         19103973      10704       1784.8       1706.0          0      597992       5819.9  cudaEventRecord                \n",
      "      0.0           664958       1123        592.1        625.0          0       12193        780.5  cuGetProcAddress               \n",
      "      0.0            37276         18       2070.9       1035.0        854       18178       4032.2  cudaEventCreateWithFlags       \n",
      "      0.0            10444          3       3481.3       3347.0       3216        3881        352.3  cuInit                         \n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                                                  Name                                                \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------------------------------------------------\n",
      "     21.0        384162698       8232    46667.0    40021.0     38931     90412      16273.1  ampere_sgemm_64x32_sliced1x4_tn                                                                     \n",
      "     14.5        265155402         49  5411334.7  5404509.0   5394009   5555303      31306.2  ampere_sgemm_128x128_tn                                                                             \n",
      "     13.9        254451076       4705    54081.0    46199.0      3073    125886      24799.9  void at::native::<unnamed>::indexSelectLargeIndex<float, long, unsigned int, (int)2, (int)2, (int)-…\n",
      "     12.0        219056141       2352    93136.1    92941.0     91917     97808        894.0  ampere_sgemm_128x32_tn                                                                              \n",
      "      7.9        144460192       2304    62699.7    62991.5      5730    121851      34200.7  void at::native::<unnamed>::CatArrayBatchedCopy<float, unsigned int, (int)4, (int)128, (int)1>(T1 *…\n",
      "      4.2         76744578       2328    32965.9    29199.0      7267     66081      12959.0  void gemv2N_kernel<int, int, float, float, float, float, (int)128, (int)2, (int)4, (int)4, (int)1, …\n",
      "      3.9         71435866       2328    30685.5    25901.0      7491     64672      13020.8  std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, float, float, float, float, (bool…\n",
      "      3.3         60293017        196   307617.4   306678.5    305269    312602       2100.3  void at::native::mbtopk::radixFindKthValues<float, unsigned int, unsigned int, (int)2>(at::cuda::de…\n",
      "      3.1         56557985         49  1154244.6  1154230.0   1151318   1157720       1507.0  void at::native::<unnamed>::cunn_SoftMaxForward<(int)4, float, float, float, at::native::<unnamed>:…\n",
      "      2.6         47774135        216   221176.6   257375.0    104147    379227     110247.5  ampere_sgemm_128x64_tn                                                                              \n",
      "      1.8         33414036       1324    25237.2     3618.0      2561    587456     109922.3  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      1.5         27388320       5976     4583.1     3810.0      2145     50266       3424.2  void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<float>, at::deta…\n",
      "      1.4         25359149       7252     3496.8     3458.0      3169     11653        884.9  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      1.1         20354093       2449     8311.2     7619.0      2016     50745       5889.0  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<float, float, floa…\n",
      "      1.0         18735852         49   382364.3   367445.0    337638    467269      36027.3  void at::native::mbtopk::gatherTopK<float, unsigned int, (int)2>(at::cuda::detail::TensorInfo<T1, T…\n",
      "      0.9         16991613       3849     4414.6     4035.0      1920     34418       4101.7  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<float, float, floa…\n",
      "      0.9         16991100       3626     4685.9     4642.0      4514      6692        204.4  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::MeanOps<fl…\n",
      "      0.6         11846056       4826     2454.6     1985.0      1921     34834       2291.6  void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<float>, at…\n",
      "      0.5          9959088       3626     2746.6     2689.0      2433      8676        613.1  void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::pow_tensor_scala…\n",
      "      0.5          9792306       4900     1998.4     1985.0      1952      2497         60.8  void at::native::unrolled_elementwise_kernel<at::native::CUDAFunctorOnSelf_add<long>, at::detail::A…\n",
      "      0.4          7448565       3626     2054.2     2018.0      1984      2688         74.5  void at::native::vectorized_elementwise_kernel<(int)4, at::native::rsqrt_kernel_cuda(at::TensorIter…\n",
      "      0.4          7078945       2450     2889.4     2850.0      2402      4067        137.9  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<float, at::native::func_wrapp…\n",
      "      0.3          5719524       1200     4766.3     4130.0      3394     34609       4187.5  void at::native::vectorized_elementwise_kernel<(int)4, void at::native::<unnamed>::pow_tensor_scala…\n",
      "      0.3          5442235       1200     4535.2     3939.0      3393     34896       4250.6  void at::native::vectorized_elementwise_kernel<(int)4, at::native::tanh_kernel_cuda(at::TensorItera…\n",
      "      0.3          5136535       2550     2014.3     1986.0      1952      2498         65.8  void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnSelf_add<long>, at:…\n",
      "      0.3          4925600       2450     2010.4     1985.0      1952      2498         64.5  void at::native::vectorized_elementwise_kernel<(int)2, at::native::CUDAFunctorOnSelf_add<long>, at:…\n",
      "      0.2          4576212       1584     2889.0     2818.0      2722      5956        349.3  void <unnamed>::softmax_warp_forward<float, float, float, (int)5, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.2          3609521        144    25066.1    14888.0     11174     49944      16529.0  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      0.2          3435861         48    71580.4    71908.0     51481     95792      19240.3  ampere_sgemm_128x128_nn                                                                             \n",
      "      0.2          3263906         96    33999.0    33920.5      5922     62559      27993.3  void at::native::<unnamed>::indexSelectLargeIndex<float, long, unsigned int, (int)-1, (int)-1, (int…\n",
      "      0.1          2075883        196    10591.2    10597.0     10213     11271        199.8  void at::native::mbtopk::computeBlockwiseWithinKCounts<unsigned int>(T1 *, short *, unsigned int, i…\n",
      "      0.1          1325042        408     3247.7     3233.0      3105      3874        112.4  void <unnamed>::softmax_warp_forward<float, float, float, (int)6, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0           640345         24    26681.0    26669.0     26477     26957        128.2  std::enable_if<!T7, void>::type internal::gemvx::kernel<int, int, float, float, float, float, (bool…\n",
      "      0.0           508330        192     2647.6     2625.0      2592      3010         65.5  void <unnamed>::softmax_warp_forward<float, float, float, (int)4, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0           482797        149     3240.2     3073.0      2273      4387        596.2  void at::native::unrolled_elementwise_kernel<at::native::<unnamed>::direct_copy_kernel_cuda(at::Ten…\n",
      "      0.0           472771         98     4824.2     4898.0      4482      5474        249.5  void at_cuda_detail::cub::DeviceScanByKeyKernel<at_cuda_detail::cub::DeviceScanByKeyPolicy<at_cuda_…\n",
      "      0.0           374353        199     1881.2     1857.0      1792      2497         89.9  void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<long>, at::detail::A…\n",
      "      0.0           309893         49     6324.3     6308.0      6178      6787        115.7  void at::native::bitonicSortKVInPlace<float, long, (int)2, (int)-1, at::native::GTOp<float, (bool)1…\n",
      "      0.0           298798         49     6097.9     5891.0      5730      7972        589.0  void at::native::mbtopk::computeBlockwiseKthCounts<unsigned int>(T1 *, short *, unsigned int, unsig…\n",
      "      0.0           297755        149     1998.4     1921.0      1824      2562        148.4  void <unnamed>::elementwise_kernel_with_index<int, at::native::arange_cuda_out(const c10::Scalar &,…\n",
      "      0.0           291851         49     5956.1     5955.0      4834      6404        226.2  void at::native::index_elementwise_kernel<(int)128, (int)4, void at::native::gpu_index_kernel<void …\n",
      "      0.0           291246        148     1967.9     1889.0      1824      2593        141.1  void at::native::vectorized_elementwise_kernel<(int)4, at::native::FillFunctor<float>, at::detail::…\n",
      "      0.0           271397         24    11308.2    11301.0     11237     11431         51.9  void gemmk1_kernel<int, float, (int)256, (int)5, (bool)0, (bool)0, (bool)0, (bool)0, cublasGemvTens…\n",
      "      0.0           241879         96     2519.6     2497.0      2464      2818         77.2  void <unnamed>::softmax_warp_forward<float, float, float, (int)3, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0           223503         49     4561.3     4610.0      3938      4771        154.8  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<bool, at::native::func_wrappe…\n",
      "      0.0           217028         99     2192.2     2177.0      1985      2625        112.6  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BinaryFunctor<long, long, long, …\n",
      "      0.0           199684         99     2017.0     2016.0      1952      2561         82.3  void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctorOnOther_add<float>, a…\n",
      "      0.0           181441         98     1851.4     1826.0      1792      2241         67.8  void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ReduceByKeyScanTileState<unsign…\n",
      "      0.0           162514         49     3316.6     3329.0      3074      3618         92.8  void at::native::<unnamed>::CatArrayBatchedCopy<long, unsigned int, (int)2, (int)128, (int)1>(T1 *,…\n",
      "      0.0           162030         48     3375.6     3393.5      3201      3490         78.2  void at::native::<unnamed>::CatArrayBatchedCopy<float, unsigned int, (int)3, (int)128, (int)1>(T1 *…\n",
      "      0.0           154443         51     3028.3     3266.0      2305      3554        392.8  void at::native::unrolled_elementwise_kernel<at::native::<unnamed>::direct_copy_kernel_cuda(at::Ten…\n",
      "      0.0           147847         49     3017.3     2978.0      2945      3330         79.4  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<long, long, long, …\n",
      "      0.0           139457         49     2846.1     2849.0      2496      3298        156.3  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      0.0           137800         49     2812.2     2784.0      2689      3107         92.7  void at::native::elementwise_kernel<(int)128, (int)4, void at::native::gpu_kernel_impl<at::native::…\n",
      "      0.0           136637         64     2135.0     2129.0      2016      2530         85.3  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<long, long, bool, …\n",
      "      0.0           133242         49     2719.2     2626.0      2592      3234        149.8  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<long, long, long, …\n",
      "      0.0           120922         49     2467.8     2402.0      2369      2721         89.9  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      0.0           117785         48     2453.9     2401.0      2337      2690         95.3  void <unnamed>::softmax_warp_forward<float, float, float, (int)2, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0           115320         50     2306.4     2305.0      2113      2690        121.1  void at::native::vectorized_elementwise_kernel<(int)4, at::native::log_kernel_cuda(at::TensorIterat…\n",
      "      0.0           112917         50     2258.3     2273.0      2081      2433         71.8  void at::native::vectorized_elementwise_kernel<(int)4, at::native::<unnamed>::where_kernel_impl(at:…\n",
      "      0.0           106517         49     2173.8     2145.0      2112      2530         78.3  void at::native::mbtopk::fill<unsigned int, unsigned int>(T1 *, T1, T2)                             \n",
      "      0.0           105243         49     2147.8     2113.0      1986      2528        106.9  void at::native::vectorized_elementwise_kernel<(int)4, at::native::neg_kernel_cuda(at::TensorIterat…\n",
      "      0.0            60547         24     2522.8     2497.0      2465      2786         89.2  void <unnamed>::softmax_warp_forward<float, float, float, (int)1, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0            54234         24     2259.8     2241.0      2241      2401         33.9  void <unnamed>::softmax_warp_forward<float, float, float, (int)0, (bool)0, (bool)0>(T2 *, const T1 …\n",
      "      0.0            50361         25     2014.4     2017.0      1984      2144         34.3  void at::native::unrolled_elementwise_kernel<at::native::BUnaryFunctor<long, long, bool, at::native…\n",
      "      0.0            24400         12     2033.3     2018.0      2016      2113         29.0  void at::native::vectorized_elementwise_kernel<(int)2, at::native::BUnaryFunctor<long, long, bool, …\n",
      "      0.0            21803          4     5450.8     5251.0      3458      7843       1928.9  void at::native::<unnamed>::indexSelectSmallIndex<float, long, unsigned int, (int)2, (int)2, (int)-…\n",
      "      0.0             6788          2     3394.0     3394.0      2946      3842        633.6  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<long, at::native::func_wrappe…\n",
      "      0.0             5025          2     2512.5     2512.5      2433      2592        112.4  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<long, long, long, …\n",
      "      0.0             4644          2     2322.0     2322.0      2306      2338         22.6  void at::native::vectorized_elementwise_kernel<(int)4, at::native::CUDAFunctor_add<long>, at::detai…\n",
      "      0.0             4450          1     4450.0     4450.0      4450      4450          0.0  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<bool, at::native::func_wrappe…\n",
      "      0.0             3715          1     3715.0     3715.0      3715      3715          0.0  void at::native::reduce_kernel<(int)512, (int)1, at::native::ReduceOp<long, at::native::func_wrappe…\n",
      "      0.0             3394          1     3394.0     3394.0      3394      3394          0.0  void at::native::<unnamed>::indexSelectLargeIndex<long, long, unsigned int, (int)2, (int)2, (int)-2…\n",
      "      0.0             3298          1     3298.0     3298.0      3298      3298          0.0  void at::native::<unnamed>::indexSelectLargeIndex<long, long, unsigned int, (int)1, (int)1, (int)-2…\n",
      "      0.0             2754          1     2754.0     2754.0      2754      2754          0.0  void at::native::vectorized_elementwise_kernel<(int)4, at::native::BUnaryFunctor<long, long, bool, …\n",
      "      0.0             2753          1     2753.0     2753.0      2753      2753          0.0  void at::native::elementwise_kernel<(int)128, (int)2, void at::native::gpu_kernel_impl<at::native::…\n",
      "      0.0             2209          1     2209.0     2209.0      2209      2209          0.0  void at::native::vectorized_elementwise_kernel<(int)4, at::native::AbsFunctor<long>, at::detail::Ar…\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)   StdDev (ns)      Operation     \n",
      " --------  ---------------  -----  --------  --------  --------  ---------  -----------  ------------------\n",
      "     84.9        477684094   3161  151118.0     864.0       800  104668127    2629658.3  [CUDA memcpy HtoD]\n",
      "     10.2         57591973  29450    1955.6    1952.0      1888       3361         61.8  [CUDA memcpy DtoD]\n",
      "      3.1         17638611  17603    1002.0     992.0       545       1986         66.6  [CUDA memcpy DtoH]\n",
      "      1.7          9771245  10802     904.6     896.0       800       2753        121.3  [CUDA memset]     \n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "   4919.325   3161     1.556     0.000     0.000  1024.459       25.875  [CUDA memcpy HtoD]\n",
      "      5.812  10802     0.001     0.000     0.000     0.012        0.001  [CUDA memset]     \n",
      "      0.216  29450     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoD]\n",
      "      0.114  17603     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /notebooks/GPT-J-model-comparison/report_Pytorch.nsys-rep\n",
      "    /notebooks/GPT-J-model-comparison/report_Pytorch.sqlite\n"
     ]
    }
   ],
   "source": [
    "#Now that I have the model running as expected, I can generate the output from the Nvidia profiler to see the outputs.\n",
    "!nsys profile -t cuda,nvtx --stats=true --force-overwrite=true -o report_Pytorch python MT5-Pytorch.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7547c-ed81-4090-a88b-64101e014cf3",
   "metadata": {},
   "source": [
    "## Running MT5 TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3eda1b-7d67-43bd-8130-1bb48bf36485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-15T22:21:12.180175Z",
     "iopub.status.busy": "2023-07-15T22:21:12.179526Z",
     "iopub.status.idle": "2023-07-15T22:22:44.428486Z",
     "shell.execute_reply": "2023-07-15T22:22:44.427561Z",
     "shell.execute_reply.started": "2023-07-15T22:21:12.180147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: LBR backtrace method is not supported on this platform. DWARF backtrace method will be used.\n",
      "You are using a model of type mt5 to instantiate a model of type t5. This is not supported for all configurations of models and can yield errors.\n",
      "Found GPU at: /device:GPU:0\n",
      "Downloading tf_model.h5: 100%|██████████| 4.58G/4.58G [00:40<00:00, 121MB/s] \n",
      "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
      "\n",
      "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at google/mt5-large.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n",
      "['<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in', '<extra_id_0> weiter verhandelt werden muss in Syrien <extra_id_1> sagt, dass weiter verhandelt werden muss in Syrien <extra_id_2> verhandelt muss in Syrien <extra_id_3> verhandelt muss in Syrien <extra_id_4> verhandelt muss in Syrien <extra_id_5> verhandelt muss in']\n",
      "Generating '/tmp/nsys-report-715b.qdstrm'\n",
      "[1/7] [========================100%] report_TF.nsys-rep\n",
      "[2/7] [========================100%] report_TF.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /notebooks/GPT-J-model-comparison/report_TF.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)   Max (ns)   StdDev (ns)               Name              \n",
      " --------  ---------------  ---------  -----------  -----------  ---------  ---------  -----------  -------------------------------\n",
      "     25.9       1192050456          2  596025228.0  596025228.0  197003340  995047116  564302165.7  cudaFree                       \n",
      "     20.9        960575624         36   26682656.2   26008390.5   23382886   32025138    2178852.2  cuModuleLoadData               \n",
      "     17.5        802721065      83412       9623.6       8966.0          0     207361       5451.7  cudaLaunchKernel               \n",
      "     13.0        597377300      82316       7257.1       6388.0          0     257316       4338.1  cuLaunchKernel                 \n",
      "     11.4        525497282       2170     242164.6      10072.5          0  106609350    3250321.6  cuMemcpyHtoDAsync_v2           \n",
      "      6.4        293634871       1192     246338.0       3737.5          0    3746262     828050.9  cuStreamSynchronize            \n",
      "      0.8         38237361       3552      10765.0       9875.5          0      58383       4668.3  cudaMemsetAsync                \n",
      "      0.8         36600933          1   36600933.0   36600933.0   36600933   36600933          0.0  cuMemAlloc_v2                  \n",
      "      0.7         32607394       6768       4817.9       4443.0          0      50870       2939.7  cudaEventQuery                 \n",
      "      0.6         27652283       1096      25230.2      18574.5          0     240112      25287.9  cuMemcpyDtoHAsync_v2           \n",
      "      0.6         25474358      22344       1140.1        949.0          0     106760       1525.9  cudaStreamGetCaptureInfo_v10010\n",
      "      0.3         14781617       6768       2184.0       2020.0          0      46929       2077.5  cudaEventRecord                \n",
      "      0.3         11745562       4330       2712.6       2501.0          0      47046       2167.8  cuEventQuery                   \n",
      "      0.2          9992649       6628       1507.6       1316.5          0      46515       1681.7  cuEventRecord                  \n",
      "      0.2          8957546       3266       2742.7       2602.0          0      47927       2445.9  cuStreamWaitEvent              \n",
      "      0.2          7245687         48     150951.8     147471.5     132057     197549      14606.3  cuModuleLoadFatBinary          \n",
      "      0.1          6269430        583      10753.7       7183.0          0      56085       7386.2  cudaMemcpyAsync                \n",
      "      0.0          1854818          2     927409.0     927409.0     882861     971957      63000.4  cuMemHostAlloc                 \n",
      "      0.0           822847       1123        732.7        661.0        478      14075        433.9  cuGetProcAddress               \n",
      "      0.0           791688          3     263896.0     208292.0       5220     578176     290497.0  cudaMalloc                     \n",
      "      0.0            88191          2      44095.5      44095.5      18179      70012      36651.5  cuMemGetInfo_v2                \n",
      "      0.0            50960          5      10192.0       3002.0       2360      29900      11884.8  cuStreamCreate                 \n",
      "      0.0            19567         18       1087.1        923.5        803       3228        555.8  cudaEventCreateWithFlags       \n",
      "      0.0            15665          1      15665.0      15665.0      15665      15665          0.0  cuMemsetD32_v2                 \n",
      "      0.0            10831          3       3610.3       3252.0       3106       4473        750.6  cuInit                         \n",
      "      0.0            10348          6       1724.7       1232.5        850       4517       1404.4  cuEventCreate                  \n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances   Avg (ns)    Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                                                  Name                                                \n",
      " --------  ---------------  ---------  ----------  ----------  --------  --------  -----------  ----------------------------------------------------------------------------------------------------\n",
      "     16.2        384494999       9408     40868.9     37978.5      3039    118062      21362.9  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<float, (int)4>, int, (bool)1, (bool)0>(co…\n",
      "     12.6        297922617      15384     19365.7     17501.0     16317     43194       6627.0  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_32x6_nn_align4>(T1::Params)                \n",
      "     10.6        252240795       9412     26799.9      5439.0      2111    123341      31503.3  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      7.7        182589753         98   1863160.7   1862117.5   1641447   2090915     219413.3  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x128_16x3_nn_align4>(T1::Params)              \n",
      "      7.2        170080573      30606      5557.1      3168.0      2239   3002904      39607.7  AddV2_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                  \n",
      "      6.1        143663961      28514      5038.4      4096.0      2176   3004665      25413.6  Mul_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                    \n",
      "      6.0        143075574       4656     30729.3     32027.0     13309     67157      11000.6  void gemv2N_kernel<int, int, float, float, float, float, (int)128, (int)8, (int)4, (int)4, (int)1, …\n",
      "      5.5        130189643       4704     27676.4     28539.0      5759     67350      12465.5  void gemv2T_kernel_val<int, int, float, float, float, float, (int)128, (int)16, (int)2, (int)2, (bo…\n",
      "      5.3        125608905       2354     53359.8     52184.0     50424   1479520      41565.1  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_256x64_16x4_nn_align4>(T1::Params)               \n",
      "      3.7         86999754       3216     27052.2     31355.0      7742     36123       8799.7  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_nn_align4>(T1::Params)                \n",
      "      3.0         71776566         98    732413.9    718083.0    622465    900792      62630.9  void tensorflow::impl::TopKKernel<float>(const T1 *, int, int, bool, T1 *, int *)                   \n",
      "      2.7         63007865       4994     12616.7      3487.0      3231    586408      66263.7  _ZN10tensorflow94_GLOBAL__N__64_tmpxft_000177f5_00000000_12_softmax_op_gpu_cu_compute_80_cpp1_ii_fa…\n",
      "      1.6         39019270       1200     32516.1     31451.0     30651     85427       7386.9  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x64_16x6_nn_align4>(T1::Params)               \n",
      "      1.2         28494372        312     91328.1     90690.0     45336    136875      34880.0  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_128x128_16x5_nn_align4>(T1::Params)              \n",
      "      1.0         22785593         98    232506.1    232492.5    176678    288436      55692.3  void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, cub::Max>::Policy6…\n",
      "      1.0         22664402         98    231269.4    231404.5    174822    287509      55456.5  _ZN3cub27DeviceSegmentedReduceKernelINS_18DeviceReducePolicyIffiNS_3SumEE9Policy600ENS_22TransformI…\n",
      "      1.0         22600292       7496      3015.0      3008.0      2655      5855        274.2  void cub::DeviceSegmentedReduceKernel<cub::DeviceReducePolicy<float, float, int, tensorflow::functo…\n",
      "      0.9         21149060       7496      2821.4      2816.0      2398      8863        495.3  Square_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                 \n",
      "      0.9         20274049       2594      7815.7      6112.0      2432     42106       4269.2  Pow_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                    \n",
      "      0.7         17094219       3216      5315.4      6207.0      2463      7007       1563.9  void splitKreduce_kernel<(int)32, (int)16, int, float, float, float, float, (bool)1, (bool)0, (bool…\n",
      "      0.7         16395335       7496      2187.2      2175.0      2111      3041        109.7  Rsqrt_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                  \n",
      "      0.6         14484488       4896      2958.4      3008.0      2303      6112        303.5  _ZN10tensorflow7functor15RowReduceKernelIN3cub22TransformInputIteratorIfNS_94_GLOBAL__N__64_tmpxft_…\n",
      "      0.6         13957884        435     32087.1     19869.0      6047   2645743     125927.8  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::NormalDistribution<tenso…\n",
      "      0.6         13408584       4896      2738.7      2783.0      2175      5247        260.1  void tensorflow::functor::RowReduceKernel<const float *, float *, cub::Max>(T1, T2, int, int, T3, s…\n",
      "      0.5         11935373          1  11935373.0  11935373.0  11935373  11935373          0.0  void tensorflow::functor::FillPhiloxRandomKernelLaunch<tensorflow::random::TruncatedNormalDistribut…\n",
      "      0.4         10407996       2496      4169.9      3616.0      2462     34362       3393.1  Tanh_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                   \n",
      "      0.4          9352102        864     10824.2      3200.0      3135     62167      15128.7  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.3          5955787        784      7596.7      7423.0      7326      8542        310.5  void cub::DeviceSegmentedRadixSortKernel<cub::DeviceRadixSortPolicy<float, int, int>::Policy700, (b…\n",
      "      0.2          5098518        392     13006.4     11213.5     10238     19709       3753.6  void cub::DeviceSegmentedRadixSortKernel<cub::DeviceRadixSortPolicy<float, int, int>::Policy700, (b…\n",
      "      0.1          2023724         48     42160.9     42218.0     32219     52215       9812.1  ampere_sgemm_128x128_nn                                                                             \n",
      "      0.1          1262267         48     26297.2     26284.5     20445     32475       5809.2  void cutlass::Kernel<cutlass_80_tensorop_s1688gemm_64x64_16x6_tn_align1>(T1::Params)                \n",
      "      0.0          1162182        510      2278.8      2271.0      2016      2879        171.2  Cast_GPU_DT_INT32_DT_FLOAT_kernel                                                                   \n",
      "      0.0          1114912        494      2256.9      2272.0      2111      2655        100.4  LogicalAnd_GPU_DT_BOOL_DT_BOOL_kernel                                                               \n",
      "      0.0          1020069        406      2512.5      2591.5      2144      3039        183.9  Div_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                    \n",
      "      0.0           872863        294      2968.9      2847.5      2751      3582        222.7  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<int, (int)2>, int, (bool)1, (bool)0>(cons…\n",
      "      0.0           795494        288      2762.1      2751.0      2559      3200         85.4  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           680553        296      2299.2      2111.0      2047      4191        433.2  Cast_GPU_DT_BOOL_DT_FLOAT_kernel                                                                    \n",
      "      0.0           648733        208      3118.9      2927.5      2464      6942        609.2  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<float, (int)4>, int, (bool)1>(const T1 *,…\n",
      "      0.0           589375        224      2631.1      2496.0      2303      3263        187.1  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           520885        144      3617.3      3616.0      3423      4192        154.2  void gemmSN_TN_kernel<float, (int)128, (int)16, (int)2, (int)4, (int)6, (int)7, (bool)0, cublasGemv…\n",
      "      0.0           513868        204      2519.0      2464.0      2304      2880        161.6  Sub_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                    \n",
      "      0.0           503377        196      2568.3      2591.0      2430      3008        103.3  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           496592        196      2533.6      2527.0      2464      2912         68.6  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<float, (int)1>, int, (bool)1, (bool)0>(co…\n",
      "      0.0           475157        144      3299.7      3295.0      3232      3710         68.5  void gemmSN_NN_kernel<float, (int)256, (int)4, (int)2, (int)8, (int)5, (int)4, (bool)0, cublasGemvT…\n",
      "      0.0           470797        200      2354.0      2336.0      2271      2752         80.3  void tensorflow::functor::BlockReduceKernel<bool *, bool *, (int)256, tensorflow::functor::And>(T1,…\n",
      "      0.0           462492        198      2335.8      2304.0      2175      2720         80.9  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           459042        100      4590.4      4463.5      2432     10591       1901.8  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           455264         48      9484.7      9566.5      7647     11455       1810.6  void gemmk1_kernel<int, float, (int)256, (int)5, (bool)0, (bool)0, (bool)0, (bool)0, cublasGemvTens…\n",
      "      0.0           448201        198      2263.6      2272.0      2143      2687         92.2  LogicalOr_GPU_DT_BOOL_DT_BOOL_kernel                                                                \n",
      "      0.0           448124        196      2286.3      2272.0      2207      2624         67.3  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           445522        196      2273.1      2271.0      2207      2688         58.5  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           440507        198      2224.8      2208.0      2048      2560         63.1  LogicalNot_GPU_DT_BOOL_DT_BOOL_kernel                                                               \n",
      "      0.0           437591        196      2232.6      2239.0      2175      2624         64.3  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           422913        196      2157.7      2144.0      2111      2560         65.4  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           312945         96      3259.8      3264.0      3103      3360         48.9  _ZN3cub23DeviceSelectSweepKernelINS_16DispatchSelectIfINS_21CountingInputIteratorIilEENS_22Transfor…\n",
      "      0.0           290122        102      2844.3      2847.0      2272      3359        169.3  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           289516         98      2954.2      2943.0      2816      3199         85.6  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           282873         98      2886.5      2879.0      2784      3103         60.3  void tensorflow::functor::SwapDimension1And2InTensor3UsingTiles<unsigned int, (int)256, (int)32, (i…\n",
      "      0.0           273493        102      2681.3      2687.0      2303      3007        101.6  SelectV2_GPU_DT_FLOAT_DT_FLOAT_kernel                                                               \n",
      "      0.0           269066        104      2587.2      2688.0      2303      3200        203.0  Log_GPU_DT_FLOAT_DT_FLOAT_kernel                                                                    \n",
      "      0.0           252935         96      2634.7      2591.5      2527      3104        104.6  void cub::DeviceReduceSingleTileKernel<cub::DeviceReducePolicy<bool, int, int, cub::Sum>::Policy600…\n",
      "      0.0           252760         98      2579.2      2528.0      2464      2975         91.8  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<int, (int)1>, int, (bool)1, (bool)0>(cons…\n",
      "      0.0           249941         98      2550.4      2496.0      2463      2879         86.1  void tensorflow::GatherOpKernel<tensorflow::AlignedVector<bool, (int)1>, int, (bool)1, (bool)0>(con…\n",
      "      0.0           245878         96      2561.2      2592.0      2304      2879        115.5  NotEqual_GPU_DT_FLOAT_DT_BOOL_kernel                                                                \n",
      "      0.0           244258        100      2442.6      2400.0      2240      2816         96.7  Less_GPU_DT_FLOAT_DT_BOOL_kernel                                                                    \n",
      "      0.0           241182        106      2275.3      2240.0      2143      2849        119.9  SelectV2_GPU_DT_INT32_DT_INT32_kernel                                                               \n",
      "      0.0           238513        100      2385.1      2368.0      2175      2752         58.0  void tensorflow::functor::RowReduceKernel<float *, float *, tensorflow::functor::MinPropagateNaN>(T…\n",
      "      0.0           235387         98      2401.9      2400.0      2304      2719         63.8  void tensorflow::functor::RowReduceKernel<bool *, bool *, tensorflow::functor::And>(T1, T2, int, in…\n",
      "      0.0           228411         98      2330.7      2335.0      2303      2655         45.5  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0           225018         96      2343.9      2336.0      2175      2720         72.6  AddV2_GPU_DT_INT64_DT_INT64_kernel                                                                  \n",
      "      0.0           221030         96      2302.4      2303.0      2208      2623         56.7  fusion                                                                                              \n",
      "      0.0           220898         94      2350.0      2335.0      2271      2752         87.0  void tensorflow::functor::BlockReduceKernel<long *, long *, (int)256, tensorflow::functor::MaxPropa…\n",
      "      0.0           218279        104      2098.8      2080.0      2047      2272         39.1  Cast_GPU_DT_FLOAT_DT_INT32_kernel                                                                   \n",
      "      0.0           216479         96      2255.0      2208.0      2175      2592         92.6  void tensorflow::functor::PropagateWhereIndicesKernel<(int)1, int>(T2, Eigen::array<T2, T1>, long *)\n",
      "      0.0           188010         96      1958.4      1952.0      1919      2240         43.0  void cub::DeviceCompactInitKernel<cub::ScanTileState<int, (bool)1>, int *>(T1, int, T2)             \n",
      "      0.0            53016          2     26508.0     26508.0     18877     34139      10791.9  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0             9566          4      2391.5      2399.5      2239      2528        158.2  Cast_GPU_DT_BOOL_DT_INT32_kernel                                                                    \n",
      "      0.0             9117          4      2279.3      2271.5      2271      2303         15.8  void tensorflow::functor::ShuffleInTensor3Simple<unsigned int, (int)0, (int)2, (int)1, (bool)0>(int…\n",
      "      0.0             6367          2      3183.5      3183.5      3039      3328        204.4  void Eigen::internal::EigenMetaKernel<Eigen::TensorEvaluator<const Eigen::TensorAssignOp<Eigen::Ten…\n",
      "      0.0             5983          2      2991.5      2991.5      2688      3295        429.2  void tensorflow::functor::BlockReduceKernel<bool *, bool *, (int)256, tensorflow::functor::Or>(T1, …\n",
      "      0.0             4415          2      2207.5      2207.5      2207      2208          0.7  void tensorflow::functor::RowReduceKernel<bool *, bool *, tensorflow::functor::Or>(T1, T2, int, int…\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)   StdDev (ns)      Operation     \n",
      " --------  ---------------  -----  --------  --------  --------  ---------  -----------  ------------------\n",
      "     97.7        471648723   2170  217349.6    1055.0       831  106480896    3238384.5  [CUDA memcpy HtoD]\n",
      "      0.9          4225636    583    7248.1    2048.0      2015    3000249     124170.5  [CUDA memcpy DtoD]\n",
      "      0.8          3679944   1096    3357.6    1120.0       960      74709       8075.1  [CUDA memcpy DtoH]\n",
      "      0.7          3203739   3553     901.7     896.0       831       1311         59.2  [CUDA memset]     \n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "   4949.926   2170     2.281     0.003     0.000  1024.459       31.204  [CUDA memcpy HtoD]\n",
      "   1024.467    583     1.757     0.000     0.000  1024.459       42.429  [CUDA memcpy DtoD]\n",
      "     65.261   1096     0.060     0.002     0.000     1.921        0.210  [CUDA memcpy DtoH]\n",
      "      0.497   3553     0.000     0.000     0.000     0.001        0.000  [CUDA memset]     \n",
      "\n",
      "Generated:\n",
      "    /notebooks/GPT-J-model-comparison/report_TF.nsys-rep\n",
      "    /notebooks/GPT-J-model-comparison/report_TF.sqlite\n"
     ]
    }
   ],
   "source": [
    "#Now that I have the model running as expected, I can generate the output from the Nvidia profiler to see the outputs.\n",
    "#Running this for GPT-Neo\n",
    "!nsys profile -t cuda,nvtx --stats=true --force-overwrite=true -o report_TF python MT5-TensorFlow.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
